{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e8dbe87",
      "metadata": {
        "cellId": "dsjmeuiu5ooqr5um2elwq",
        "execution_id": "63041a91-be5f-4ca8-9fcc-ca840d96b49c",
        "id": "3e8dbe87"
      },
      "source": [
        "## Обучение генеративной трансформерной модели с помощью `transformers`\n",
        "\n",
        "В этой работе мы познакомимся на практике с процессом тренировки большой трансформерной языковой модели. Поскольку такая тренировка требует существенных вычислительных ресурсов, выполнять эту работу рекомендуется в Yandex DataSphere, в которой доступны вычислитльные узлы с одни или двумя графическими процессорами Tesla V100.\n",
        "\n",
        "### Архитектура трансформеров\n",
        "\n",
        "В рамках этой работы мы предполагаем, что вы уже знакомы с архитектурой трансформеров, например, по [статье из ML-хэндбука](https://academy.yandex.ru/handbook/ml/article/transformery). Также для первоначального знакомства рекомендую заметку [Jay Alammar. The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/), и её частичный [русскоязычный перевод](https://habr.com/ru/articles/486358/).\n",
        "\n",
        "Мы не будем в рамках работы создавать архитетуру нейросети \"с нуля\". Если вам инетересно изучить реализацию трансформеров - рекомендую посмотреть на [NanoGPT](https://github.com/karpathy/nanoGPT). Подробно эта реализация разбирается в [этом видео](https://www.youtube.com/watch?v=kCc8FmEb1nY).\n",
        "\n",
        "### Библиотека `transformers` и её друзья\n",
        "\n",
        "Стандартом де факто в реализации трансформеров служит библиотека `transformers` от [HuggingFace](http://huggingface.co). Она содержит в себе реализацию большого количества используемых трансформерных архитектур, а также ряд полезных инструментов для их обучения. Многие инструменты также оформлены в виде отдельных библиотек, которые хорошо работают вместе:\n",
        "\n",
        "* `tokenizers` - быстрая реализация различных токенизаторов, позволяющих разделять входной текст на токены\n",
        "* `datasets` - манипулирование большими датасетами\n",
        "* `evaluate` - вычисление различных метрик и оценка результатов обучения\n",
        "* `accelerate` - реализация вычислений на множестве GPU и на вычислительных кластерах\n",
        "\n",
        "Для начала, установим необходимые библиотеки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ac5909a2",
      "metadata": {
        "cellId": "rbd025oj0my1im4ob4369",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:06:06.004559Z",
          "iopub.status.busy": "2023-11-22T13:06:06.003903Z",
          "iopub.status.idle": "2023-11-22T13:06:17.327182Z",
          "shell.execute_reply": "2023-11-22T13:06:17.325725Z",
          "shell.execute_reply.started": "2023-11-22T13:06:06.004524Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac5909a2",
        "outputId": "8aa04caf-4fc1-46a9-f3aa-9f0fcaf92cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.0+cu121)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-3.0.2 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers tokenizers datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c343afb",
      "metadata": {
        "cellId": "ksyl1g4026iecxq8gx3y7i",
        "execution_id": "1ca722bd-54d0-49cb-ba0f-f31785d40372",
        "id": "4c343afb"
      },
      "source": [
        "В текущем варианте при работе в DataSphere возникают проблемы при использовании файлового хранилища. Для решения проблем нам нужно установить последнюю версию библиотеки `s3fs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0a581a6a",
      "metadata": {
        "cellId": "ung9q52gkel6fodtt5ncyx",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:06:22.446953Z",
          "iopub.status.busy": "2023-11-22T13:06:22.446097Z",
          "iopub.status.idle": "2023-11-22T13:06:34.003628Z",
          "shell.execute_reply": "2023-11-22T13:06:34.002501Z",
          "shell.execute_reply.started": "2023-11-22T13:06:22.446896Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a581a6a",
        "outputId": "e48dfcfa-6c12-4ae7-cc0a-7206d07f2f10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/dask/s3fs\n",
            "  Cloning https://github.com/dask/s3fs to /tmp/pip-req-build-c1z4w41r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/dask/s3fs /tmp/pip-req-build-c1z4w41r\n",
            "  Resolved https://github.com/dask/s3fs to commit f3f63cbfbfe71a4355abd63cafd8c678c4a5a0af\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs==2024.10.0)\n",
            "  Downloading aiobotocore-2.15.2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting fsspec==2024.10.0.* (from s3fs==2024.10.0)\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from s3fs==2024.10.0) (3.10.10)\n",
            "Collecting botocore<1.35.37,>=1.35.16 (from aiobotocore<3.0.0,>=2.5.4->s3fs==2024.10.0)\n",
            "  Downloading botocore-1.35.36-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs==2024.10.0) (1.16.0)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs==2024.10.0)\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (4.0.3)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs==2024.10.0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs==2024.10.0) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs==2024.10.0) (2.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs==2024.10.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.37,>=1.35.16->aiobotocore<3.0.0,>=2.5.4->s3fs==2024.10.0) (1.16.0)\n",
            "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiobotocore-2.15.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.35.36-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: s3fs\n",
            "  Building wheel for s3fs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for s3fs: filename=s3fs-2024.10.0-py3-none-any.whl size=29855 sha256=50f7848bd085fb8034c7349bc545f435e7147d5170cb90433bb57f6556cb8820\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m9l8c7vc/wheels/1c/2c/ca/bd47ad7042338ff00f37a24b19e98e1374da8e22b72baf14a6\n",
            "Successfully built s3fs\n",
            "Installing collected packages: jmespath, fsspec, aioitertools, botocore, aiobotocore, s3fs\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.0.2 requires fsspec[http]<=2024.9.0,>=2023.1.0, but you have fsspec 2024.10.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiobotocore-2.15.2 aioitertools-0.12.0 botocore-1.35.36 fsspec-2024.10.0 jmespath-1.0.1 s3fs-2024.10.0\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade git+https://github.com/dask/s3fs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc3f15e8",
      "metadata": {
        "cellId": "26xvyymzgf9rbljkfquk3",
        "execution_id": "ed5b5cd9-8b09-47c2-aefc-76c2e1b11867",
        "id": "bc3f15e8"
      },
      "source": [
        "### Подготовка датасета\n",
        "\n",
        "В нашем примере, мы будем обучать виртуального Льва Толстого. Для этого, возьмём все основные романы писателя, и подготовим их них датасет. В качестве отправной точки будет использовать тексты из [библиотеки Мошкова](http://lib.ru). Соберем ссылки на романы Анна Каренина, Война и Мир и др. в один список:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "44d7ffcc",
      "metadata": {
        "cellId": "iclg75lmp4eq0s1e06tgz8",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:06:34.006420Z",
          "iopub.status.busy": "2023-11-22T13:06:34.005468Z",
          "iopub.status.idle": "2023-11-22T13:06:34.023538Z",
          "shell.execute_reply": "2023-11-22T13:06:34.022313Z",
          "shell.execute_reply.started": "2023-11-22T13:06:34.006372Z"
        },
        "id": "44d7ffcc"
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0039.shtml\",\n",
        "    \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0040.shtml\",\n",
        "    \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0050.shtml\",\n",
        "    \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0060.shtml\",\n",
        "    \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0070.shtml\",\n",
        "    \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0080.shtml\",\n",
        "    \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_0090.shtml\",\n",
        "    \"http://az.lib.ru/t/tolstoj_lew_nikolaewich/text_1860_dekabristy.shtml\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "305027b2",
      "metadata": {
        "cellId": "tckha1m6ce8l6uzswytdo",
        "execution_id": "79951af7-53d9-4ec2-aa1c-c6fb34818c24",
        "id": "305027b2"
      },
      "source": [
        "Теперь скачаем все материалы и подготовим из них один большой текстовый файл. Для того нам понадобится убрать HTML-теги, а также несколько первоначальных строчек в каждом из файлов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "84ed7313",
      "metadata": {
        "cellId": "nnln4ab6z2rmu8k09ydl",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:06:37.190694Z",
          "iopub.status.busy": "2023-11-22T13:06:37.189627Z",
          "iopub.status.idle": "2023-11-22T13:06:38.738412Z",
          "shell.execute_reply": "2023-11-22T13:06:38.737280Z",
          "shell.execute_reply.started": "2023-11-22T13:06:37.190658Z"
        },
        "id": "84ed7313"
      },
      "outputs": [],
      "source": [
        "import html\n",
        "import re\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "def download(url):\n",
        "    return requests.get(url).text\n",
        "\n",
        "\n",
        "# code borrowed from here: https://github.com/pallets/markupsafe/blob/0.23/markupsafe/__init__.py#L21\n",
        "striptags_re = re.compile(r\"(<!--.*?-->|<[^>]*>)\")\n",
        "entity_re = re.compile(r\"&([^;]+);\")\n",
        "\n",
        "\n",
        "def to_text(s):\n",
        "    return html.unescape(striptags_re.sub(\"\", s))\n",
        "\n",
        "\n",
        "def beautify(s):\n",
        "    lines = [x.strip() for x in s.split(\"\\n\") if x.strip() != \"\"]\n",
        "    for i in range(min(100, len(lines))):\n",
        "        if lines[i] == \"-->\":\n",
        "            break\n",
        "    return \"\\n\".join(lines[i + 1 :] if i < 100 else lines)\n",
        "\n",
        "\n",
        "with open(\"dataset.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for u in urls:\n",
        "        text = beautify(to_text(download(u)))\n",
        "        f.write(text + \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32dd8e6a",
      "metadata": {
        "cellId": "4djmsjyt9wpdh9l8h9j3l",
        "execution_id": "24bf09e3-9b1f-47bd-940a-f59f19e01073",
        "id": "32dd8e6a"
      },
      "source": [
        "В результате мы получили один большой файл `dataset.txt`, содержащий большой корпус текстов Льва Толстого.\n",
        "\n",
        "### Датасеты в Yandex DataSphere\n",
        "\n",
        "При использовании Yandex DataSphere, у нас ограничен объем данных, которые мы можем хранить вместе с проектом. Обычно, большие объемы данных в облаке хранят в **объектном хранилище S3**. DataSphere позволяет легко подключаться к таким хранилищам, монтируя их как обычную директорию в проекте, после чего можно получить доступ к данным как к обычным файлам.\n",
        "\n",
        "Однако, доступ в хранилище S3 не слишком быстрый, а для обучения сетей хочется отдавать данные как можно быстрее, не тормозя вычислительный процесс. Для этого в DataSphere предусмотрены **датасеты** - это отдельные виртуальные накопители, которые можно легко подключать к различным вычислительным ресурсам.\n",
        "\n",
        "Будучи созданным, датасет не может быть изменён - это обеспечивает сохранность исходных данных. Хорошим стилем считается хранить все данные для обучения моделей в датасетах. Кроме того, датасеты можно разделять между другими участниками сообщества или проекта.\n",
        "\n",
        "В нашем случае объем обучающих данных небольшой, и можно обойтись без создания датасета. Но если вы хотите попробовать - добавьте ниже ячейку со следующим кодом и запустите его:\n",
        "```\n",
        "#!:bash\n",
        "#pragma dataset init mytext --size 1Gb\n",
        "cp dataset.txt /home/jupyter/mnt/datasets/mytext\n",
        "```\n",
        "Это создаст датасет `mytext` с единственным файлом `dataset.txt`. При этом ниже в коде вам нужно будет изменить путь к файлу `dataset.txt` на `/home/jupyter/mnt/datasets/mytext/dataset.txt`.\n",
        "\n",
        "> Кажется, что в создании датасета нет большого смысла, поскольку мы просто положили тот же файл в другое место. На самом деле это не так - теперь файл `dataset.txt` не будет занимать место в хранилище проекта, доступ к нему будет быстрее, а также вы сможете легко поделиться датасетом с другими участниками команды, чтобы им не пришлось писать код по предварительной обработке данных. При этом датасет не будет копироваться, а будет просто смонтирован в соответствующие директории в DataSphere."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05b835e2",
      "metadata": {
        "cellId": "nunyvossq6o0yteon40rkk",
        "execution_id": "1b9df5be-83bf-4505-ae10-7fcd613f2ecf",
        "id": "05b835e2"
      },
      "source": [
        "### Токенизация\n",
        "\n",
        "Нейросети работают с числами, поэтому первым этапом является токенизация текста, т.е. разбиение его на атомарные элементы, которые затем можно добавить в словарь, и представлять текст как последовательность индексов в словаре. Текст можно токенизировать по буквам, или по словам.\n",
        "\n",
        "При построении современных генеративных сетей текст обычно разбивают на фрагменты таким образом, чтобы частота появления каждого фрагмента в тексте была примерно одинакова. Это лежит в основе т.н. Byte-Pair Encoding (BPE). Подробнее можно прочитать [в этой статье](https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt).\n",
        "\n",
        "Для обучения своего токенизатора используем библиотеку `tokenizers`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7d25b461",
      "metadata": {
        "cellId": "x7fii1yudivznf9h1jgxb",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:06:44.265151Z",
          "iopub.status.busy": "2023-11-22T13:06:44.264232Z",
          "iopub.status.idle": "2023-11-22T13:06:47.935533Z",
          "shell.execute_reply": "2023-11-22T13:06:47.934344Z",
          "shell.execute_reply.started": "2023-11-22T13:06:44.265075Z"
        },
        "id": "7d25b461"
      },
      "outputs": [],
      "source": [
        "import tokenizers as tok\n",
        "import transformers as tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e470b754",
      "metadata": {
        "cellId": "jjhwu4gsmle8v2ojdyjukv",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:06:53.487505Z",
          "iopub.status.busy": "2023-11-22T13:06:53.486439Z",
          "iopub.status.idle": "2023-11-22T13:06:56.051785Z",
          "shell.execute_reply": "2023-11-22T13:06:56.050627Z",
          "shell.execute_reply.started": "2023-11-22T13:06:53.487469Z"
        },
        "id": "e470b754"
      },
      "outputs": [],
      "source": [
        "tokenizer = tok.Tokenizer(tok.models.BPE(unk_token=\"[UNK]\"))\n",
        "tokenizer.pre_tokenizer = tok.pre_tokenizers.Whitespace()\n",
        "trainer = tok.trainers.BpeTrainer(special_tokens=[\"[PAD]\"])\n",
        "tokenizer.train([\"dataset.txt\"], trainer)\n",
        "tokenizer.enable_padding()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9147ea7e",
      "metadata": {
        "cellId": "elx7gkaggq7m8oqmajnxh",
        "execution_id": "f07d8caa-a3c4-40d8-b637-f1234bc4f642",
        "id": "9147ea7e"
      },
      "source": [
        "А данном случае мы используем два специальных токена - `[UNK]` для представления неизвестного токена (такое случится, если на вход попадёт символ, который токенизатор не видел при обучении), и `[PAD]` для **паддинга** - он используется, если нужно дополнить последовательность до определённой длины.\n",
        "\n",
        "Вот как можно закодировать входной текст:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "04579048",
      "metadata": {
        "cellId": "d1cjx8u0oy8rixk9y6m8q",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:07:08.891474Z",
          "iopub.status.busy": "2023-11-22T13:07:08.890755Z",
          "iopub.status.idle": "2023-11-22T13:07:08.922664Z",
          "shell.execute_reply": "2023-11-22T13:07:08.921593Z",
          "shell.execute_reply.started": "2023-11-22T13:07:08.891438Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04579048",
        "outputId": "9604afc2-c9e0-45dd-a32f-4cf098a30781"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Иван',\n",
              " 'С',\n",
              " 'иг',\n",
              " 'изму',\n",
              " 'н',\n",
              " 'до',\n",
              " 'вич',\n",
              " 'подошел',\n",
              " 'к',\n",
              " 'окну',\n",
              " 'и',\n",
              " 'закашлялся',\n",
              " '.',\n",
              " 'Вечер',\n",
              " 'ело',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenizer.encode(\"Иван Сигизмундович подошел к окну и закашлялся. Вечерело.\").tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156f66e2",
      "metadata": {
        "cellId": "kxbtrltl0yra2oywv2mxe",
        "id": "156f66e2"
      },
      "source": [
        "Видим, что популярные слова токенизируются целиком, а те, которые встречаются в тексте редко или не встречаются вовсе - разбиваются на фрагменты.\n",
        "\n",
        "### Генеративные трансформеры\n",
        "\n",
        "Для генерации текста используются архитектуры GPT - Generative Pre-trained Transformers. В то время как полноценные трансформеры являются энкодер-декодерной архитектурой, т.е. могут решать задачи преобразования одного вида последовательности в другую, GPT является только декодером, т.к. способно прогнозировать распределение вероятности следующего слова по начальной части последовательности.\n",
        "\n",
        "Мы используем архитектуру GPT-2, которая, с одной стороны, не слишком огромна, а с другой - может неплохо обучиться. Сперва попробуем натренировать такую архитетуру \"с нуля\".\n",
        "\n",
        "Дла начала нам потребуется преобразовать наш токенизатор к объекту `ttokenizer`, который понимает библиотека transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8928e282",
      "metadata": {
        "cellId": "76f33tr549x3izkn7g8t7w",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:07:20.166309Z",
          "iopub.status.busy": "2023-11-22T13:07:20.165368Z",
          "iopub.status.idle": "2023-11-22T13:07:20.306703Z",
          "shell.execute_reply": "2023-11-22T13:07:20.305635Z",
          "shell.execute_reply.started": "2023-11-22T13:07:20.166270Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8928e282",
        "outputId": "625f4b2b-1a5b-4601-da61-4ea48003398c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "vocab = tokenizer.get_vocab()\n",
        "ttokenizer = tr.PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91488224-b24c-44d6-a805-b4cea7ad833a",
      "metadata": {
        "id": "91488224-b24c-44d6-a805-b4cea7ad833a"
      },
      "source": [
        "Теперь создадим непосредственно нейросетевую модель GPT2. При этом основные параметры (количество слоёв, количество голов внимания и т.д. оставим по умолчанию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9b18d8be",
      "metadata": {
        "cellId": "7yflw4cbp4mapc77dbn4o",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:07:21.219041Z",
          "iopub.status.busy": "2023-11-22T13:07:21.218320Z",
          "iopub.status.idle": "2023-11-22T13:07:37.475252Z",
          "shell.execute_reply": "2023-11-22T13:07:37.474143Z",
          "shell.execute_reply.started": "2023-11-22T13:07:21.219005Z"
        },
        "id": "9b18d8be"
      },
      "outputs": [],
      "source": [
        "config = tr.GPT2Config(\n",
        "    vocab_size=len(vocab),\n",
        "    bos_token_id=tokenizer.token_to_id(\"[CLS]\"),\n",
        "    eos_token_id=tokenizer.token_to_id(\"[EOS]\"),\n",
        ")\n",
        "gpt = tr.GPT2LMHeadModel(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8379893b-f03d-48cc-b09f-7c085b15f0ce",
      "metadata": {
        "id": "8379893b-f03d-48cc-b09f-7c085b15f0ce"
      },
      "source": [
        "Веса вновь созданной модели инициализируются случайным образом, поэтому если мы попросим такую модель сгенерировать текст - получится бессмыслица:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9eec498e",
      "metadata": {
        "cellId": "pd21krza2dmw3ecnel8ara",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:07:37.478365Z",
          "iopub.status.busy": "2023-11-22T13:07:37.477330Z",
          "iopub.status.idle": "2023-11-22T13:07:39.412338Z",
          "shell.execute_reply": "2023-11-22T13:07:39.411260Z",
          "shell.execute_reply.started": "2023-11-22T13:07:37.478319Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "9eec498e",
        "outputId": "ed6366be-1a91-49d1-e261-2f8fe0f00455"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Мне нравится перегнулся перегнулся перегнулся Такой набо тщательно тщательно набо набо набо набо набо тщательно скрывает Алпатыча поздравля набо набо ем жены жены жены жены жены Бе Бе рые рые набо жены жены жены нравилась ü беспоря беспоря беспоря заведе жены жены Алексеевич ассигна Бе Бе рые повесел овес повесел повесел подумать'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "res = gpt.generate(\n",
        "    **ttokenizer(\"Мне нравится \", return_tensors=\"pt\"),\n",
        "    max_new_tokens=50,\n",
        "    top_k=3,\n",
        "    do_sample=True\n",
        ")\n",
        "ttokenizer.decode(res[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f4bd5a4-3378-4a38-ac3d-07f48ad00047",
      "metadata": {
        "id": "3f4bd5a4-3378-4a38-ac3d-07f48ad00047"
      },
      "source": [
        "Теперь нам надо научиться подавать на вход модели фрагменты текста для обучения. Для этого существует библиотека `datasets`, входящее в семейство трансформерных библиотек HuggingFace. Помимо того, что эта библиотека умеет работать с разными форматами входных датасетов, она также интегрирована с HuggingFace Hub, и может в одну строчку загружать множество имеющихся на этом сайте датасетов.\n",
        "\n",
        "В нашем случае мы загрузим датасет из текстового файла:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "04f83e7a",
      "metadata": {
        "cellId": "ymos6h01o5efyusa8fmapr",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:07:51.422222Z",
          "iopub.status.busy": "2023-11-22T13:07:51.421328Z",
          "iopub.status.idle": "2023-11-22T13:07:53.369455Z",
          "shell.execute_reply": "2023-11-22T13:07:53.368323Z",
          "shell.execute_reply.started": "2023-11-22T13:07:51.422187Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3cedb88262b446e9aae67cf90a0b29ce",
            "9634686e4c2d4750abc809b0db78d7d3",
            "714de28f74f04e628ea1ee943ae484a3",
            "8c9e4d96883a4fe4ab01dad09afc003d",
            "863778ce6b41469b8f297af13fa588bb",
            "5956eb78848443bd861bce73b06f826f",
            "83c506ac904448e09dfa986747d38add",
            "a424e35dc12c4feda56af3e719c81f82",
            "c3cb64be7a724124ada986289e1ff5d0",
            "42495bf7c21442159c2a13efb9837674",
            "50d8ffa733134ec1824b7bac8a5c6a26"
          ]
        },
        "id": "04f83e7a",
        "outputId": "f9d11aaf-8395-40ef-8983-78948f1bf003"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cedb88262b446e9aae67cf90a0b29ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'Он взял своею большою рукой меня за руку, и пожал так крепко, честно, только что не больно. Я думала, что он поцелует мою руку, и нагнулась было к нему, но он еще раз пожал мне руку и прямо в глаза посмотрел своим твердым и веселым взглядом.'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import datasets\n",
        "\n",
        "dataset = datasets.load_dataset(\"text\", data_files=\"dataset.txt\")\n",
        "dataset[\"train\"][13]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c042844-9998-4a05-bc69-165b77896fcf",
      "metadata": {
        "id": "1c042844-9998-4a05-bc69-165b77896fcf"
      },
      "source": [
        "Далее нам необходимо научиться токенизировать датасет, т.е. преобразовывать в числовые тензоры, которые затем мы будем подавать на вход нейросети в процессе обучения. Для этого опишем фукнцию `tokenize`, которая будет возвращать словарь с несколькими полями:\n",
        "\n",
        "* `input_ids` - это собственно номера слов входной последовательности в словаре\n",
        "* `token_type_ids` - содержит нули. Это поле используется в более сложных сценариях, например, когда мы тренируем сеть отвечать на вопросы по тексту. В этом случае нам нужно подать на вход текст + вопрос, и это поле позволяет различать между несколькими разными по смыслу фрагментами входной последовательности\n",
        "* `atttention_mask` показывает, какая часть входной последовательности значима. Для организации последовательности в minibatch нам может потребоваться дополнить последовательность до максимальной длины, и поле `attention_mask` содержит 1 в тех позициях, которые соответствуют исходной последовательности\n",
        "\n",
        "Такой формат входных данных типичен для трансформерной архитектуры. Также мы передаем последовательность значений целевой переменной `labels`, но поскольку наша задача - это генерация текста, то в качестве `labels` мы передаём копию исходного текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "72f7b2ad",
      "metadata": {
        "cellId": "svhzelwehjpwlu9emfsib",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:07:59.902663Z",
          "iopub.status.busy": "2023-11-22T13:07:59.901666Z",
          "iopub.status.idle": "2023-11-22T13:08:03.142172Z",
          "shell.execute_reply": "2023-11-22T13:08:03.140784Z",
          "shell.execute_reply.started": "2023-11-22T13:07:59.902606Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "aaca8ed727984ece88dd13cf77f8fd45",
            "cad47d792e0f42248ed5a77033a5f685",
            "ff99601f176c48ddbe2756bdd8955ad5",
            "4484a97d22f6463cb1b5e804b0fb326e",
            "f4bad5db460f48dc9e9c6cdeda996c37",
            "0111de54046f40f49fd22da8ab8063e5",
            "e6e689e751e749599f986d4b24075051",
            "0462fbcd11894346bc7e99b0fae85661",
            "2b1f3da3d28247fab1cbf28ead7ef123",
            "751c7bbbe14a4eb4ae8351d3fd47eba3",
            "c643d40d0be94e3e80a7ec8e17ba8105"
          ]
        },
        "id": "72f7b2ad",
        "outputId": "d92f5b23-eefd-4ba4-e450-490150d220cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/60782 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aaca8ed727984ece88dd13cf77f8fd45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [9585, 9736, 3192],\n",
              " 'token_type_ids': [0, 0, 0],\n",
              " 'attention_mask': [1, 1, 1],\n",
              " 'labels': [9585, 9736, 3192]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "def tokenize(x):\n",
        "    x = ttokenizer(x[\"text\"])\n",
        "    x[\"labels\"] = x[\"input_ids\"].copy()\n",
        "    return x\n",
        "\n",
        "\n",
        "ds = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "ds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5800b193-896c-4b68-97cf-584cd69e1880",
      "metadata": {
        "id": "5800b193-896c-4b68-97cf-584cd69e1880"
      },
      "source": [
        "Для обучения лучше всего использовать длинные фрагменты текста, поэтому мы сгруппируем все последовательности токенов в блоки размером `block_size`. Для этого мы сначала сконкатенируем все последовательности, а потом разобъем их на блоки. В данном случае мы не будем даже разбивать последовательность на слова и/или предложения - как показывает практика, такой упрощенный подход также даёт хорошие результаты.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c6b55b96",
      "metadata": {
        "cellId": "omlv6mxp3tqt8ebm0awq",
        "execution": {
          "iopub.execute_input": "2023-11-22T14:34:15.997454Z",
          "iopub.status.busy": "2023-11-22T14:34:15.996759Z",
          "iopub.status.idle": "2023-11-22T14:34:18.603876Z",
          "shell.execute_reply": "2023-11-22T14:34:18.602744Z",
          "shell.execute_reply.started": "2023-11-22T14:34:15.997410Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4de54af9838b46a0a3ad03c9de357495",
            "662af2ed971b4488ab2da113f3aae46a",
            "4eb9c8c604cc4be891991ddfefe39421",
            "298ecef830274346af85be48370ef69d",
            "eb73b9cc42f6487cb5572a136e575de5",
            "67c2588b8aca4488a27d70fcb9d50e42",
            "8208b88fe0a1404d914377b25527f055",
            "cbd69ae5e92c453498a9f798498662cd",
            "b88fdbcf573d45b7855b11987ad1b527",
            "c8650f6b493b4ea5b3f978cd7d7a18c2",
            "6af6349fd6734f2c8fa0e8d87c808462"
          ]
        },
        "id": "c6b55b96",
        "outputId": "1cec172a-cc81-45ca-bbfc-77c9bd4a527c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/60782 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4de54af9838b46a0a3ad03c9de357495"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from itertools import chain\n",
        "\n",
        "block_size = 1024\n",
        "\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    total_length = (total_length // block_size) * block_size\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "dsb = ds.map(group_texts, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd56ffd1-995d-44e0-89d6-7740a0f075b6",
      "metadata": {
        "id": "dd56ffd1-995d-44e0-89d6-7740a0f075b6"
      },
      "source": [
        "Теперь мы готовы к обучению! Для задания параметров обучения мы создаём объект `TrainingArguments`, в котором задаем директорию, куда будут записываться промежуточные результаты обучения, число эпох, скорость обучения и т.д. Затем на основе этих параметров создаём объект `Trainer`.\n",
        "\n",
        "Обратите внимание, что размер записываемой на диск сети GPT-2 может быть весьма большим (около 1.4 Gb), что может привести к исчерпанию размера вашей домашней директории в DataSphere. Исходя из этого лучше выбирать параметры `save_steps` и `num_train_epochs` таким образом, чтобы количество записываемых на диск чекпоинтов не превышало 3-5 шт.\n",
        "\n",
        "Для начала стоит попробовать пообучать сеть в течение 30-90 минут, чтобы увидеть, что она начинает складывать слова более менее правдоподобно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3408488f",
      "metadata": {
        "cellId": "4re85sxlr1hkjznsu65qq",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:08:29.022680Z",
          "iopub.status.busy": "2023-11-22T13:08:29.021433Z",
          "iopub.status.idle": "2023-11-22T13:08:56.689692Z",
          "shell.execute_reply": "2023-11-22T13:08:56.688516Z",
          "shell.execute_reply.started": "2023-11-22T13:08:29.022635Z"
        },
        "id": "3408488f"
      },
      "outputs": [],
      "source": [
        "targs = tr.TrainingArguments(\n",
        "    output_dir=\"gpt2-scratch\",\n",
        "    num_train_epochs=30,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=200,\n",
        "    save_steps=1500,\n",
        ")\n",
        "trainer = tr.Trainer(\n",
        "    gpt,\n",
        "    args=targs,\n",
        "    train_dataset=dsb[\"train\"],\n",
        "    tokenizer=ttokenizer,\n",
        "    data_collator=tr.default_data_collator,  # tr.DataCollatorForLanguageModeling(tokenizer=ttokenizer,mlm=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cee9c3a",
      "metadata": {
        "cellId": "r86o6ai2mfz02zty9jld",
        "execution": {
          "iopub.execute_input": "2023-11-22T13:09:19.335856Z",
          "iopub.status.busy": "2023-11-22T13:09:19.334770Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "8cee9c3a",
        "outputId": "f9525542-a937-46df-a297-d88487fab787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n",
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241029_091937-0b5kg9pk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/khamitov02-mipt/huggingface/runs/0b5kg9pk' target=\"_blank\">gpt2-scratch</a></strong> to <a href='https://wandb.ai/khamitov02-mipt/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/khamitov02-mipt/huggingface' target=\"_blank\">https://wandb.ai/khamitov02-mipt/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/khamitov02-mipt/huggingface/runs/0b5kg9pk' target=\"_blank\">https://wandb.ai/khamitov02-mipt/huggingface/runs/0b5kg9pk</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bcda58f-f57d-42b6-88bd-8316b31816be",
      "metadata": {
        "id": "4bcda58f-f57d-42b6-88bd-8316b31816be"
      },
      "source": [
        "Теперь посмотрим, как работает генерация:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b03fba89",
      "metadata": {
        "cellId": "leffxl7khjsji465vkdloo",
        "execution": {
          "iopub.execute_input": "2023-11-22T14:14:51.133759Z",
          "iopub.status.busy": "2023-11-22T14:14:51.132840Z",
          "iopub.status.idle": "2023-11-22T14:14:53.740387Z",
          "shell.execute_reply": "2023-11-22T14:14:53.739172Z",
          "shell.execute_reply.started": "2023-11-22T14:14:51.133700Z"
        },
        "tags": [],
        "id": "b03fba89",
        "outputId": "46dbf816-3199-4b3f-b45e-e1281e5c77b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Пьер закашлялся и что в Москве был был быть. Но она была у нее не хотелось сказать своей смерти, и он был не знал, с тем, как было видеть этого лица, которое она узнала, что она не желала, что он сам. Она подошла к ней ; я не была рада, как ни о будущем ее, о чем она не понимала этого чувства не могла понять, но не знать, что она хотела думать об этом не будет и она не могла, как и не говорила о нее, что бы сделать. Она, но ничего не могла понять, как не было не понимала, но все это легко будет у меня и о том, как можно так, а она видела она не могла сделать, как и даже как он не видела, как бы она почувствовала'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#ttokenizer = tr.PreTrainedTokenizerFast(tokenizer_object=tokenizer)\n",
        "res = gpt.generate(\n",
        "    **ttokenizer(\"Пьер закашлялся и\", return_tensors=\"pt\").to(\"cuda\"),\n",
        "    max_new_tokens=150,\n",
        "    do_sample=True\n",
        ")\n",
        "ttokenizer.decode(res[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674d8ea2-4d80-4c55-b2ae-ba94873d3483",
      "metadata": {
        "id": "674d8ea2-4d80-4c55-b2ae-ba94873d3483"
      },
      "source": [
        "Кажется, что сгенерированный текст пока ещё не слишком осмысленный. Но сравните его с первоначальным текстом, сгенерированным необученной нейросетью - в нём почти не было корректных грамматических конструкций. За примерно час обучения сеть уже стала неплохо понимать, какие слова хорошо сочетаются друг с другом, и в целом начала говорить более осмысленно. Помните, что трансформерная модель - сложная, и для обучения полноценной GPT-2 \"с нуля\" требуются сотни и тысячи GPU-часов.\n",
        "\n",
        "> Прежде, чем переходить к следующим экспериментам, очистим память. Если вдруг на следующем этапе возникнет переполнение памяти GPU, может потребоваться перезапуск ядра ноутбука - выберите к меню Kernel -> Restart Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5903b42d",
      "metadata": {
        "cellId": "c5wv13vypc4shk1wncy5cm",
        "execution": {
          "iopub.execute_input": "2023-11-22T14:16:34.824292Z",
          "iopub.status.busy": "2023-11-22T14:16:34.823428Z",
          "iopub.status.idle": "2023-11-22T14:16:35.140660Z",
          "shell.execute_reply": "2023-11-22T14:16:35.139479Z",
          "shell.execute_reply.started": "2023-11-22T14:16:34.824254Z"
        },
        "id": "5903b42d",
        "outputId": "ca0b540d-b197-4e24-d13a-72c1d9574a31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "gpt = None\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70215e43-c58e-4182-bda1-726a0b5c8939",
      "metadata": {
        "id": "70215e43-c58e-4182-bda1-726a0b5c8939"
      },
      "source": [
        "## До-обучение GPT-2\n",
        "\n",
        "За приемлемое время сложно достичь приемлемого качества обучения трансформера, поэтому обычно используют предобученные модели (поэтому в названии GPT и фигурирует слово *Pretrained*), которые уже научились \"читать\" на нужном языке, и их необходимо лишь немного \"доучить\" под требуемую предметную область или стиль. В этом случае процесс обучения модели почти не отличается от того, что мы делали ранее - с той лишь разницей, что необходимо использовать токенизатор, который использовался при обучении исходной модели.\n",
        "\n",
        "Для начала, загрузим предобученную модель **ruGPT** и соответствующий токенизатор, и посмотрим, как эта модель умеет продолжать текст:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bafd8bbd-77e9-442a-a36a-3d1883568f83",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-22T14:38:05.664573Z",
          "iopub.status.busy": "2023-11-22T14:38:05.663434Z",
          "iopub.status.idle": "2023-11-22T14:38:29.085092Z",
          "shell.execute_reply": "2023-11-22T14:38:29.083780Z",
          "shell.execute_reply.started": "2023-11-22T14:38:05.664535Z"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "804f6bce89204af090408c175fe13b18",
            "b3386569b8204b9eb7f19fb2e9fa1bd3",
            "97d9c578fdd44553837c24568b8f774a",
            "51797b9af4b340b5b6ab1844261f2004"
          ]
        },
        "id": "bafd8bbd-77e9-442a-a36a-3d1883568f83",
        "outputId": "ef09d80e-1f0f-49e0-ca81-3b1005826708"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "804f6bce89204af090408c175fe13b18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3386569b8204b9eb7f19fb2e9fa1bd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.json:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97d9c578fdd44553837c24568b8f774a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51797b9af4b340b5b6ab1844261f2004",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Мне нравится, что вы \\nне знаете, кто вы и что вы.\\n\\n- Я знаю только, кто вы, - сказала она. - Вы -\\n\\nнесколько человек.\\n\\n- Вы -\\n\\nне совсем\\n\\nчеловек.\\n\\n- Я'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = tr.AutoTokenizer.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n",
        "gpt = tr.GPT2LMHeadModel.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n",
        "res = gpt.generate(\n",
        "    **tokenizer(\"Мне нравится, что вы \", return_tensors=\"pt\"),\n",
        "    max_new_tokens=50,\n",
        "    top_k=3,\n",
        "    do_sample=True\n",
        ")\n",
        "tokenizer.decode(res[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "616cda96-ac15-49fe-ad2c-d7762cf9bf8d",
      "metadata": {
        "id": "616cda96-ac15-49fe-ad2c-d7762cf9bf8d"
      },
      "source": [
        "На самом деле качество модели *очень сильно* зависит от количества параметров, и тот факт, что мы взяли модель **ruGPTsmall** сказывается на качестве текста. Но зато и процесс обучения будет существенно быстрее!\n",
        "\n",
        "Поскольку мы теперь используем другой токенизатор, то нам нужно заново токенизировать датасет:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66a6b616-0bb8-4ade-89c6-846643699ac0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-22T14:39:23.217520Z",
          "iopub.status.busy": "2023-11-22T14:39:23.216267Z",
          "iopub.status.idle": "2023-11-22T14:39:26.558165Z",
          "shell.execute_reply": "2023-11-22T14:39:26.556877Z",
          "shell.execute_reply.started": "2023-11-22T14:39:23.217453Z"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "03c50add30d84007b56bb75d5e3f7dee"
          ]
        },
        "id": "66a6b616-0bb8-4ade-89c6-846643699ac0",
        "outputId": "65050669-3500-460b-d8fc-676d16f4dd29"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03c50add30d84007b56bb75d5e3f7dee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/60779 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = datasets.load_dataset(\"text\", data_files=\"dataset.txt\")\n",
        "ds = dataset.map(lambda x:\n",
        "                 tokenizer(x[\"text\"]), batched=True, remove_columns=[\"text\"])\n",
        "dsb = ds.map(group_texts, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f324969-e2ed-4085-862d-906ab5bf9777",
      "metadata": {
        "id": "6f324969-e2ed-4085-862d-906ab5bf9777"
      },
      "source": [
        "Сам по себе процесс запуска обучения и указания параметров ничем не отличается от обучения трансформерной модели \"с нуля\". Возможно, при до-обучении имеет смысл указывать чуть более низкий `learning_rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ced1c5f-8a27-47c0-9dd4-276f5cd33f2d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-22T14:39:31.920477Z",
          "iopub.status.busy": "2023-11-22T14:39:31.919469Z",
          "iopub.status.idle": "2023-11-22T16:02:29.020689Z",
          "shell.execute_reply": "2023-11-22T16:02:29.019128Z",
          "shell.execute_reply.started": "2023-11-22T14:39:31.920441Z"
        },
        "tags": [],
        "id": "2ced1c5f-8a27-47c0-9dd4-276f5cd33f2d",
        "outputId": "8e5b60f4-206c-4d2d-dd21-b0f9150b84c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-22 14:39:34.067839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5700' max='5700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5700/5700 1:22:50, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.277100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.917700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.686700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.496100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>2.348400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>2.217000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>2.112400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>2.029200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.957200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.907200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.872600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOStream.flush timed out\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5700, training_loss=2.3302585534882128, metrics={'train_runtime': 4971.7497, 'train_samples_per_second': 9.154, 'train_steps_per_second': 1.146, 'total_flos': 2.378280075264e+16, 'train_loss': 2.3302585534882128, 'epoch': 30.0})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "targs = tr.TrainingArguments(\n",
        "    output_dir=\"gpt2-finetune\",\n",
        "    num_train_epochs=30,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=200,\n",
        "    save_steps=1500,\n",
        ")\n",
        "trainer = tr.Trainer(\n",
        "    gpt,\n",
        "    args=targs,\n",
        "    train_dataset=dsb[\"train\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=tr.default_data_collator,  # tr.DataCollatorForLanguageModeling(tokenizer=ttokenizer,mlm=False)\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc9e6b4-eee1-4071-9aa1-a4b5a96a1c0a",
      "metadata": {
        "id": "9dc9e6b4-eee1-4071-9aa1-a4b5a96a1c0a"
      },
      "source": [
        "Смотрим на результат генерации после обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "548b3d10-d230-4e55-a6ae-645630603dac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-22T16:14:15.085816Z",
          "iopub.status.busy": "2023-11-22T16:14:15.084658Z",
          "iopub.status.idle": "2023-11-22T16:14:16.067040Z",
          "shell.execute_reply": "2023-11-22T16:14:16.065953Z",
          "shell.execute_reply.started": "2023-11-22T16:14:15.085770Z"
        },
        "tags": [],
        "id": "548b3d10-d230-4e55-a6ae-645630603dac",
        "outputId": "c5c9cc78-6b4c-43d4-a3c4-7e304496a5a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Мне нравится, что вы  знаете  это, и я люблю это, -- сказал он, -- и  надеюсь  на  вас.  Вы  непротивоположная, я всегда был и буду  тем и другим,  я  всегдапротивоположный.-- '"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = gpt.generate(\n",
        "    **tokenizer(\"Мне нравится, что вы \", return_tensors=\"pt\").to(\"cuda\"),\n",
        "    max_new_tokens=50,\n",
        "    top_k=3,\n",
        "    do_sample=True\n",
        ")\n",
        "tokenizer.decode(res[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7bdac8e-d3db-459f-a864-6c693a642a2e",
      "metadata": {
        "id": "a7bdac8e-d3db-459f-a864-6c693a642a2e"
      },
      "source": [
        "Кажется, что мы получили сильно более хороший результат!\n",
        "\n",
        "## Параллелизация обучения\n",
        "\n",
        "Надеюсь, вы убедились, что на DataSphere можно обучать достаточно мощные модели, однако время, затрачиваемое на обучение, всё ещё остаётся большим. Чтобы ускорить этот процесс, обычно используют параллельное обучение на нескольких GPU одновременно.\n",
        "\n",
        "Самым распространённым вариантом параллелизма является параллелизм по данным (Data Parallel Training), в котором на каждый из обучающих GPU подаётся свой поток данных (т.е. своя часть исходного датасета). При этом на каждом обучающем шаге каждый GPU вычисляет свой градиент ошибки, которые затем усредняются и используются для синхронного обновления моделей на всех обучающих процессорах.\n",
        "\n",
        "Различают два варианта обучения на нескольких GPU:\n",
        "* **Data Parallel** - обычно используется, когда несколько GPU установлены на одном компьютере. В этом случае используется почти такой же код обучения на Python, как для однопроцессорного варианта, модель оборачивается в класс `torch.nn.DataParallel`, и минибатч распределяется по нескольким доступным на данном компьютере GPU.\n",
        "* **Distributed Data Parallel** используется в более общем случае, когда есть кластер из компьютеров с GPU.\n",
        "\n",
        "Подробнее про параллельное обучения можно почитать [в руководстве PyTorch](https://pytorch.org/docs/stable/distributed.html#distributed-basics).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179c51b4-ae57-4c1a-997e-5d71eb820256",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-22T14:30:02.748101Z",
          "iopub.status.busy": "2023-11-22T14:30:02.747033Z",
          "iopub.status.idle": "2023-11-22T14:30:02.875407Z",
          "shell.execute_reply": "2023-11-22T14:30:02.874294Z",
          "shell.execute_reply.started": "2023-11-22T14:30:02.747981Z"
        },
        "tags": [],
        "id": "179c51b4-ae57-4c1a-997e-5d71eb820256"
      },
      "source": [
        "## Заключение\n",
        "\n",
        "Одна из целей данной работы заключалась в том, чтобы продемонстрировать, что обучение сложных языковых моделей с помощью современных библиотек является сравнительно простой задачей - но требующей значительных вычислительных ресурсов. Как только мы выходим за рамки вычислений, которые можно сделать за несколько часов на общедоступных инструментах типа Google Colab - у нас возникает потребность в облачных вычислительных ресурсах.\n",
        "\n",
        "Yandex DataSphere обеспечивает легкий переход от локального Jupyter Notebook или публичного облака Google Colab / Kaggle к выделенной облачной инфраструктуре в Yandex Cloud. В DataSphere вы можете:\n",
        "\n",
        "* легко настроить подключения к облачным хранилищам данных,\n",
        "* взаимодействовать с другими участниками проекта\n",
        "* использовать GitHub для контроля версий кода\n",
        "* бережливо расходовать ресурсы благодаря режиму Serverless или возможности легкого переключения между виртуальными вычислителями\n",
        "\n",
        "Для эффективной работы в DataSphere в ней необходимо немного привыкнуть, но когда этап привыкания пройдёт - вы сможете эффективно пользоваться этим инструментом и получать удовольствие от работы в нём!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5829425e-b2bb-496c-85f0-5cbe8805a798",
      "metadata": {
        "id": "5829425e-b2bb-496c-85f0-5cbe8805a798"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DataSphere Kernel",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "notebookId": "1481bb9f-dbbc-4e48-8133-aa84fa48d93b",
    "notebookPath": "sda-homeworks/train-trans/train-trans.ipynb",
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3cedb88262b446e9aae67cf90a0b29ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9634686e4c2d4750abc809b0db78d7d3",
              "IPY_MODEL_714de28f74f04e628ea1ee943ae484a3",
              "IPY_MODEL_8c9e4d96883a4fe4ab01dad09afc003d"
            ],
            "layout": "IPY_MODEL_863778ce6b41469b8f297af13fa588bb"
          }
        },
        "9634686e4c2d4750abc809b0db78d7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5956eb78848443bd861bce73b06f826f",
            "placeholder": "​",
            "style": "IPY_MODEL_83c506ac904448e09dfa986747d38add",
            "value": "Generating train split: "
          }
        },
        "714de28f74f04e628ea1ee943ae484a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a424e35dc12c4feda56af3e719c81f82",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3cb64be7a724124ada986289e1ff5d0",
            "value": 1
          }
        },
        "8c9e4d96883a4fe4ab01dad09afc003d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42495bf7c21442159c2a13efb9837674",
            "placeholder": "​",
            "style": "IPY_MODEL_50d8ffa733134ec1824b7bac8a5c6a26",
            "value": " 60782/0 [00:00&lt;00:00, 165533.53 examples/s]"
          }
        },
        "863778ce6b41469b8f297af13fa588bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5956eb78848443bd861bce73b06f826f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c506ac904448e09dfa986747d38add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a424e35dc12c4feda56af3e719c81f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c3cb64be7a724124ada986289e1ff5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42495bf7c21442159c2a13efb9837674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d8ffa733134ec1824b7bac8a5c6a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaca8ed727984ece88dd13cf77f8fd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cad47d792e0f42248ed5a77033a5f685",
              "IPY_MODEL_ff99601f176c48ddbe2756bdd8955ad5",
              "IPY_MODEL_4484a97d22f6463cb1b5e804b0fb326e"
            ],
            "layout": "IPY_MODEL_f4bad5db460f48dc9e9c6cdeda996c37"
          }
        },
        "cad47d792e0f42248ed5a77033a5f685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0111de54046f40f49fd22da8ab8063e5",
            "placeholder": "​",
            "style": "IPY_MODEL_e6e689e751e749599f986d4b24075051",
            "value": "Map: 100%"
          }
        },
        "ff99601f176c48ddbe2756bdd8955ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0462fbcd11894346bc7e99b0fae85661",
            "max": 60782,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b1f3da3d28247fab1cbf28ead7ef123",
            "value": 60782
          }
        },
        "4484a97d22f6463cb1b5e804b0fb326e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_751c7bbbe14a4eb4ae8351d3fd47eba3",
            "placeholder": "​",
            "style": "IPY_MODEL_c643d40d0be94e3e80a7ec8e17ba8105",
            "value": " 60782/60782 [00:07&lt;00:00, 3455.66 examples/s]"
          }
        },
        "f4bad5db460f48dc9e9c6cdeda996c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0111de54046f40f49fd22da8ab8063e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e689e751e749599f986d4b24075051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0462fbcd11894346bc7e99b0fae85661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b1f3da3d28247fab1cbf28ead7ef123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "751c7bbbe14a4eb4ae8351d3fd47eba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c643d40d0be94e3e80a7ec8e17ba8105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4de54af9838b46a0a3ad03c9de357495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_662af2ed971b4488ab2da113f3aae46a",
              "IPY_MODEL_4eb9c8c604cc4be891991ddfefe39421",
              "IPY_MODEL_298ecef830274346af85be48370ef69d"
            ],
            "layout": "IPY_MODEL_eb73b9cc42f6487cb5572a136e575de5"
          }
        },
        "662af2ed971b4488ab2da113f3aae46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67c2588b8aca4488a27d70fcb9d50e42",
            "placeholder": "​",
            "style": "IPY_MODEL_8208b88fe0a1404d914377b25527f055",
            "value": "Map: 100%"
          }
        },
        "4eb9c8c604cc4be891991ddfefe39421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbd69ae5e92c453498a9f798498662cd",
            "max": 60782,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b88fdbcf573d45b7855b11987ad1b527",
            "value": 60782
          }
        },
        "298ecef830274346af85be48370ef69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8650f6b493b4ea5b3f978cd7d7a18c2",
            "placeholder": "​",
            "style": "IPY_MODEL_6af6349fd6734f2c8fa0e8d87c808462",
            "value": " 60782/60782 [00:07&lt;00:00, 6547.31 examples/s]"
          }
        },
        "eb73b9cc42f6487cb5572a136e575de5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c2588b8aca4488a27d70fcb9d50e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8208b88fe0a1404d914377b25527f055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbd69ae5e92c453498a9f798498662cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88fdbcf573d45b7855b11987ad1b527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8650f6b493b4ea5b3f978cd7d7a18c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af6349fd6734f2c8fa0e8d87c808462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}